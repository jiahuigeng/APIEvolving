[
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.set_default_tensor_type.html",
        "api": "torch.set_default_tensor_type",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "This function has been deprecated in favor of using `torch.set_default_dtype` for managing data type and `torch.set_default_device` for device handling. The separation provides more granular control and aligns with modern development practices.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.tensor([1.2, 3]).dtype    # initial default for floating point is torch.float32",
                "output": "torch.float32"
            },
            {
                "code": "torch.set_default_tensor_type(torch.DoubleTensor)",
                "output": ""
            },
            {
                "code": "torch.tensor([1.2, 3]).dtype    # a new floating point tensor",
                "output": "torch.float64"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.1",
        "removed_in": null,
        "replaced_by": [
            "torch.set_default_dtype",
            "torch.set_default_device"
        ]
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.as_strided.html",
        "api": "torch.as_strided",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Setting a view’s strides manually with as_strided may result in undefined behavior on non-standard PyTorch backends and overlapping views.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.randn(3, 3)\nx",
                "output": "tensor([[ 0.9039,  0.6291,  1.0795],\n        [ 0.1586,  2.1939, -0.4900],\n        [-0.1909, -0.7503,  1.9355]])"
            },
            {
                "code": "t = torch.as_strided(x, (2, 2), (1, 2))\nt",
                "output": "tensor([[0.9039, 1.0795],\n        [0.6291, 0.1586]])"
            },
            {
                "code": "t = torch.as_strided(x, (2, 2), (1, 2), 1)",
                "output": "tensor([[0.6291, 0.1586],\n        [1.0795, 2.1939]])"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.ones_like.html",
        "api": "torch.ones_like",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "The `out` keyword was removed to streamline the API and encourage using alternative methods for specifying output tensors.",
        "has_examples": true,
        "examples": [
            {
                "code": "input = torch.empty(2, 3)",
                "output": ""
            },
            {
                "code": "torch.ones_like(input)",
                "output": "tensor([[ 1.,  1.,  1.],\n        [ 1.,  1.,  1.]])"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "0.4",
        "removed_in": "0.4",
        "replaced_by": "torch.ones(input.size(), out=output)"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.zeros_like.html",
        "api": "torch.zeros_like",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The `out` keyword is no longer supported in this API as it was redundant and inconsistent with newer design principles.",
        "has_examples": true,
        "examples": [
            {
                "code": "input = torch.empty(2, 3)",
                "output": ""
            },
            {
                "code": "torch.zeros_like(input)",
                "output": "tensor([[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]])"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "0.4.0",
        "removed_in": null,
        "replaced_by": "torch.zeros(input.size(), out=output)"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.range.html",
        "api": "torch.range",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Behavior is inconsistent with Python’s `range()` builtin, and torch.arange provides a more predictable alternative.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.range(1, 4)",
                "output": "tensor([ 1.,  2.,  3.,  4.])"
            },
            {
                "code": "torch.range(1, 4, 0.5)",
                "output": "tensor([ 1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000])"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": "3.0",
        "replaced_by": "torch.arange"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.logspace.html",
        "api": "torch.logspace",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "The `steps` argument was made mandatory to improve clarity and consistency in API behavior.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.logspace(start=-10, end=10, steps=5)",
                "output": "tensor([ 1.0000e-10,  1.0000e-05,  1.0000e+00,  1.0000e+05,  1.0000e+10])"
            },
            {
                "code": "torch.logspace(start=0.1, end=1.0, steps=5)",
                "output": "tensor([  1.2589,   2.1135,   3.5481,   5.9566,  10.0000])"
            },
            {
                "code": "torch.logspace(start=0.1, end=1.0, steps=1)",
                "output": "tensor([1.2589])"
            },
            {
                "code": "torch.logspace(start=2, end=2, steps=1, base=2)",
                "output": "tensor([4.0])"
            }
        ],
        "examples_count": 4,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.11",
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.linspace.html",
        "api": "torch.linspace",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "The `steps` parameter was made mandatory to ensure explicit and consistent behavior when generating linearly spaced tensors.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.linspace(3, 10, steps=5)",
                "output": "tensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])"
            },
            {
                "code": "torch.linspace(-10, 10, steps=5)",
                "output": "tensor([-10.,  -5.,   0.,   5.,  10.])"
            },
            {
                "code": "torch.linspace(start=-10, end=10, steps=5)",
                "output": "tensor([-10.,  -5.,   0.,   5.,  10.])"
            },
            {
                "code": "torch.linspace(start=-10, end=10, steps=1)",
                "output": "tensor([-10.])"
            }
        ],
        "examples_count": 4,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.11",
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.concatenate.html",
        "api": "torch.concatenate",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "To unify functionality under `torch.cat` for clarity and consistency in API naming.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.0",
        "removed_in": "2.3",
        "replaced_by": "torch.cat"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.chunk.html",
        "api": "torch.chunk",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Added torch.tensor_split to explicitly guarantee the number of resulting chunks, addressing scenarios where torch.chunk's behavior may lead to fewer chunks than specified.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.arange(11).chunk(6)",
                "output": "(tensor([0, 1]),\n tensor([2, 3]),\n tensor([4, 5]),\n tensor([6, 7]),\n tensor([8, 9]),\n tensor([10]))"
            },
            {
                "code": "torch.arange(12).chunk(6)",
                "output": "(tensor([0, 1]),\n tensor([2, 3]),\n tensor([4, 5]),\n tensor([6, 7]),\n tensor([8, 9]),\n tensor([10, 11]))"
            },
            {
                "code": "torch.arange(13).chunk(6)",
                "output": "(tensor([0, 1, 2]),\n tensor([3, 4, 5]),\n tensor([6, 7, 8]),\n tensor([ 9, 10, 11]),\n tensor([12]))"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.tensor_split"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.conj.html",
        "api": "torch.conj",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Future versions of `torch.conj()` may return a non-writeable view for tensors of non-complex dtype. This change enhances compatibility and safety.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j])\nx.is_conj()",
                "output": "False"
            },
            {
                "code": "y = torch.conj(x)\ny.is_conj()",
                "output": "True"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.column_stack.html",
        "api": "torch.column_stack",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "The API's functionality was clarified as equivalent to `torch.hstack` while reshaping zero or one-dimensional tensors for greater usability alignment.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor([1, 2, 3])",
                "output": ""
            },
            {
                "code": "b = torch.tensor([4, 5, 6])",
                "output": ""
            },
            {
                "code": "torch.column_stack((a, b))",
                "output": "tensor([[1, 4],\n    [2, 5],\n    [3, 6]])"
            },
            {
                "code": "a = torch.arange(5)",
                "output": ""
            },
            {
                "code": "b = torch.arange(10).reshape(5, 2)",
                "output": ""
            },
            {
                "code": "torch.column_stack((a, b, b))",
                "output": "tensor([[0, 0, 1, 0, 1],\n        [1, 2, 3, 2, 3],\n        [2, 4, 5, 4, 5],\n        [3, 6, 7, 6, 7],\n        [4, 8, 9, 8, 9]])"
            }
        ],
        "examples_count": 6,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.hsplit.html",
        "api": "torch.hsplit",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Attempt to align the behavior of hsplit more closely with NumPy's hsplit, offering better consistency for splitting tensors horizontally.",
        "has_examples": true,
        "examples": [
            {
                "code": "t = torch.arange(16.0).reshape(4,4)\nt",
                "output": "tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.]])"
            },
            {
                "code": "torch.hsplit(t, 2)",
                "output": "(tensor([[ 0.,  1.],\n         [ 4.,  5.],\n         [ 8.,  9.],\n         [12., 13.]]),\n tensor([[ 2.,  3.],\n         [ 6.,  7.],\n         [10., 11.],\n         [14., 15.]]))"
            },
            {
                "code": "torch.hsplit(t, [3, 6])",
                "output": "(tensor([[ 0.,  1.,  2.],\n         [ 4.,  5.,  6.],\n         [ 8.,  9., 10.],\n         [12., 13., 14.]]),\n tensor([[ 3.],\n         [ 7.],\n         [11.],\n         [15.]]),\n tensor([], size=(4, 0)))"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.movedim.html",
        "api": "torch.movedim",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Standardized alignment with NumPy's moveaxis functionality to improve API consistency.",
        "has_examples": true,
        "examples": [
            {
                "code": "t = torch.randn(3,2,1)\nt",
                "output": "tensor([[[-0.3362],\n        [-0.8437]],\n\n        [[-0.9627],\n        [ 0.1727]],\n\n        [[ 0.5173],\n        [-0.1398]]])"
            },
            {
                "code": "torch.movedim(t, 1, 0).shape",
                "output": "torch.Size([2, 3, 1])"
            },
            {
                "code": "torch.movedim(t, 1, 0)",
                "output": "tensor([[[-0.3362],\n        [-0.9627],\n        [ 0.5173]],\n\n        [[-0.8437],\n        [ 0.1727],\n        [-0.1398]]])"
            },
            {
                "code": "torch.movedim(t, (1, 2), (0, 1)).shape",
                "output": "torch.Size([2, 1, 3])"
            },
            {
                "code": "torch.movedim(t, (1, 2), (0, 1))",
                "output": "tensor([[[-0.3362, -0.9627,  0.5173]],\n\n        [[-0.8437,  0.1727, -0.1398]]])"
            }
        ],
        "examples_count": 5,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.moveaxis.html",
        "api": "torch.moveaxis",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "To maintain consistency with other PyTorch APIs and align naming conventions, `torch.moveaxis` was marked as an alias for `torch.movedim`. The goal is to promote the use of `torch.movedim` across the codebase.",
        "has_examples": true,
        "examples": [
            {
                "code": "t = torch.randn(3,2,1)\nt",
                "output": "tensor([[[-0.3362],\n        [-0.8437]],\n\n        [[-0.9627],\n        [ 0.1727]],\n\n        [[ 0.5173],\n        [-0.1398]]])"
            },
            {
                "code": "torch.moveaxis(t, 1, 0).shape",
                "output": "torch.Size([2, 3, 1])"
            },
            {
                "code": "torch.moveaxis(t, 1, 0)",
                "output": "tensor([[[-0.3362],\n        [-0.9627],\n        [ 0.5173]],\n\n        [[-0.8437],\n        [ 0.1727],\n        [-0.1398]]])"
            },
            {
                "code": "torch.moveaxis(t, (1, 2), (0, 1)).shape",
                "output": "torch.Size([2, 1, 3])"
            },
            {
                "code": "torch.moveaxis(t, (1, 2), (0, 1))",
                "output": "tensor([[[-0.3362, -0.9627,  0.5173]],\n\n        [[-0.8437,  0.1727, -0.1398]]])"
            }
        ],
        "examples_count": 5,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.8.0",
        "removed_in": "2.0.0",
        "replaced_by": "torch.movedim"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.row_stack.html",
        "api": "torch.row_stack",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "torch.row_stack is an alias for torch.vstack; to simplify the API surface and prevent redundancy, users are encouraged to use torch.vstack directly.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": null,
        "replaced_by": "torch.vstack"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/torch.html#torch.select",
        "api": "torch.select",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "RuntimeError raised for sparse tensors when a view cannot be returned. Users are directed to use torch.select_copy() for compatibility.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.zeros(1, requires_grad=True)",
                "output": ""
            },
            {
                "code": "with torch.no_grad():\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "is_train = False",
                "output": ""
            },
            {
                "code": "with torch.set_grad_enabled(is_train):\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "torch.set_grad_enabled(True)  # this can also be used as a function",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "True"
            },
            {
                "code": "torch.set_grad_enabled(False)",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "False"
            }
        ],
        "examples_count": 8,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.select_copy"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.narrow_copy.html",
        "api": "torch.narrow_copy",
        "package": "PyTorch",
        "change_type": "",
        "reason": "This API provides a copy-based method specifically for sparse tensors since the original torch.narrow does not support shared storage narrowing for sparse tensors.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])",
                "output": ""
            },
            {
                "code": "torch.narrow_copy(x, 0, 0, 2)",
                "output": "tensor([[ 1,  2,  3],\n        [ 4,  5,  6]])"
            },
            {
                "code": "torch.narrow_copy(x, 1, 1, 2)",
                "output": "tensor([[ 2,  3],\n        [ 5,  6],\n        [ 8,  9]])"
            },
            {
                "code": "s = torch.arange(16).reshape(2, 2, 2, 2).to_sparse(2)",
                "output": ""
            },
            {
                "code": "torch.narrow_copy(s, 0, 0, 1)",
                "output": "tensor(indices=tensor([[0, 0],\n                       [0, 1]]),\n       values=tensor([[[0, 1],\n                       [2, 3]],\n\n                      [[4, 5],\n                       [6, 7]]]),\n       size=(1, 2, 2, 2), nnz=2, layout=torch.sparse_coo)"
            }
        ],
        "examples_count": 5,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.squeeze.html",
        "api": "torch.squeeze",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "Enhancement to allow the `dim` parameter to accept tuples of dimensions for better usability and flexibility.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.zeros(2, 1, 2, 1, 2)\nx.size()",
                "output": "torch.Size([2, 1, 2, 1, 2])"
            },
            {
                "code": "y = torch.squeeze(x)\ny.size()",
                "output": "torch.Size([2, 2, 2])"
            },
            {
                "code": "y = torch.squeeze(x, 0)\ny.size()",
                "output": "torch.Size([2, 1, 2, 1, 2])"
            },
            {
                "code": "y = torch.squeeze(x, 1)\ny.size()",
                "output": "torch.Size([2, 2, 1, 2])"
            },
            {
                "code": "y = torch.squeeze(x, (1, 2, 3))",
                "output": "torch.Size([2, 2, 2])"
            }
        ],
        "examples_count": 5,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.swapdims.html",
        "api": "torch.swapdims",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "torch.swapdims is an alias for the existing `torch.transpose` API and mirrors NumPy's `swapaxes` for familiarity. The documentation clarifies this equivalence without introducing breaking changes.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\nx",
                "output": "tensor([[[0, 1],\n        [2, 3]],\n\n        [[4, 5],\n        [6, 7]]])"
            },
            {
                "code": "torch.swapdims(x, 0, 1)",
                "output": "tensor([[[0, 1],\n        [4, 5]],\n\n        [[2, 3],\n        [6, 7]]])"
            },
            {
                "code": "torch.swapdims(x, 0, 2)",
                "output": "tensor([[[0, 4],\n        [2, 6]],\n\n        [[1, 5],\n        [3, 7]]])"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.vsplit.html",
        "api": "torch.vsplit",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "The `torch.vsplit` function was added for convenience as a specific alias to `torch.tensor_split` for vertical splitting which has similar functionality but enforces stricter input rules for `indices_or_sections` to avoid runtime errors.",
        "has_examples": true,
        "examples": [
            {
                "code": "t = torch.arange(16.0).reshape(4,4)\nt",
                "output": "tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.]])"
            },
            {
                "code": "torch.vsplit(t, 2)",
                "output": "(tensor([[0., 1., 2., 3.],\n         [4., 5., 6., 7.]]),\n tensor([[ 8.,  9., 10., 11.],\n         [12., 13., 14., 15.]]))"
            },
            {
                "code": "torch.vsplit(t, [3, 6])",
                "output": "(tensor([[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.]]),\n tensor([[12., 13., 14., 15.]]),\n tensor([], size=(0, 4)))"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.tensor_split"
    },
    {
        "source_url": "https://github.com/pytorch/pytorch/releases/tag/v1.6.0",
        "api": "torch.save",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "The `torch.save` API switched to a zipfile-based file format in PyTorch 1.6, introducing new serialization behavior to optimize storage handling.",
        "has_examples": true,
        "examples": [
            {
                "code": "import torch\ntorch.tensor(3) / torch.tensor(2)",
                "output": "../aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer\ndivision of tensors using div or / is deprecated, and in a future\nrelease div will perform true division as in Python 3. Use true_divide\nor floor_divide (// in Python) instead.\ntensor(1)"
            },
            {
                "code": "import torch\ntorch.tensor(3) / torch.tensor(2)\n# NB: the following is equivalent to",
                "output": "../aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer\ndivision of tensors using div or / is deprecated, and in a future\nrelease div will perform true division as in Python 3. Use true_divide\nor floor_divide (// in Python) instead.\ntensor(1)"
            },
            {
                "code": "import torch\n# torch.floor_divide(torch.tensor(3), torch.tensor(2))",
                "output": ""
            },
            {
                "code": "import torch\ntorch.tensor(3) // torch.tensor(2)\n# NB: the following is equivalent to",
                "output": "tensor(1)"
            },
            {
                "code": "import torch\n# torch.floor_divide(torch.tensor(3), torch.tensor(2))",
                "output": ""
            },
            {
                "code": "import torch\ntorch.tensor(3) // torch.tensor(2)",
                "output": "tensor(1)"
            },
            {
                "code": "import torch\ninput = torch.tensor(0)",
                "output": ""
            },
            {
                "code": "import torch\ntensor = torch.tensor(1)",
                "output": ""
            },
            {
                "code": "import torch\nother = torch.tensor(3)",
                "output": ""
            },
            {
                "code": "import torch\nvalue = 1",
                "output": ""
            },
            {
                "code": "import torch\ntorch.addcdiv(input, tensor, other, value=value)",
                "output": "../aten/src/ATen/native/PointwiseOps.cpp:81: UserWarning:\nInteger division with addcdiv is deprecated, and in a future \nrelease addcdiv will perform a true division of tensor1 and\ntensor2. The current addcdiv behavior can be replicated using\nfloor_divide for integral inputs (self + value * tensor1 // tensor2)\nand division for float inputs (self + value * tensor1 / tensor2).\nThe new addcdiv behavior can be implemented with\ntrue_divide (self + value * torch.true_divide(tensor1, tensor2).\ntensor(0)"
            },
            {
                "code": "import torch\ninput = torch.tensor(0)",
                "output": ""
            },
            {
                "code": "import torch\ntensor = torch.tensor(1)",
                "output": ""
            },
            {
                "code": "import torch\nother = torch.tensor(3)",
                "output": ""
            },
            {
                "code": "import torch\nvalue = 1",
                "output": ""
            },
            {
                "code": "import torch\ntorch.addcdiv(input, tensor, other, value=value)",
                "output": "../aten/src/ATen/native/PointwiseOps.cpp:81: UserWarning:\nInteger division with addcdiv is deprecated, and in a future \nrelease addcdiv will perform a true division of tensor1 and\ntensor2. The current addcdiv behavior can be replicated using\nfloor_divide for integral inputs (self + value * tensor1 // tensor2)\nand division for float inputs (self + value * tensor1 / tensor2).\nThe new addcdiv behavior can be implemented with\ntrue_divide (self + value * torch.true_divide(tensor1, tensor2).\ntensor(0)"
            },
            {
                "code": "import torch\ninput = torch.tensor(0)",
                "output": ""
            },
            {
                "code": "import torch\ntensor = torch.tensor(1)",
                "output": ""
            },
            {
                "code": "import torch\nother = torch.tensor(3)",
                "output": ""
            },
            {
                "code": "import torch\nvalue = 1",
                "output": ""
            },
            {
                "code": "import torch\n(input + torch.floor_divide(value * tensor, other))",
                "output": "tensor(0)"
            },
            {
                "code": "import torch\ninput = torch.tensor(0)",
                "output": ""
            },
            {
                "code": "import torch\ntensor = torch.tensor(1)",
                "output": ""
            },
            {
                "code": "import torch\nother = torch.tensor(3)",
                "output": ""
            },
            {
                "code": "import torch\nvalue = 1",
                "output": ""
            },
            {
                "code": "import torch\n(input + torch.floor_divide(value * tensor, other))",
                "output": "tensor(0)\n      \n\ntorch.tensor(5, device='cuda:0') + torch.tensor((1, 1), device='cuda:1')"
            },
            {
                "code": "import torch\ntorch.tensor(5, device='cuda:0') + torch.tensor((1, 1), device='cuda:1')",
                "output": "torch.tensor([6, 6], device='cuda:1')"
            },
            {
                "code": "import torch\ntorch.tensor(5, device='cuda:0') + torch.tensor((1, 1), device='cuda:1')",
                "output": "torch.tensor([6, 6], device='cuda:1')"
            },
            {
                "code": "import torch\ntorch.tensor(5, device='cuda:0').to('cuda:1') + torch.tensor((1, 1), device='cuda:1')",
                "output": "torch.tensor([6, 6], device='cuda:1')"
            },
            {
                "code": "import torch\ntorch.tensor(5, device='cuda:0').to('cuda:1') + torch.tensor((1, 1), device='cuda:1')",
                "output": "torch.tensor([6, 6], device='cuda:1')"
            },
            {
                "code": "import torch\ntorch.tensor([-2, -1, -0.9, 0, 0.9, 1, 2], dtype=torch.bool)",
                "output": "tensor([ True,  True, False, False, False,  True,  True])"
            },
            {
                "code": "import torch\ntorch.tensor([-2, -1, -0.9, 0, 0.9, 1, 2], dtype=torch.bool)",
                "output": "tensor([ True,  True, False, False, False,  True,  True])"
            },
            {
                "code": "import torch\ntorch.tensor([-2, -1, -0.9, 0, 0.9, 1, 2]).long().bool()",
                "output": "tensor([ True,  True, False, False, False,  True,  True])"
            },
            {
                "code": "import torch\ntorch.tensor([-2, -1, -0.9, 0, 0.9, 1, 2]).long().bool()",
                "output": "tensor([ True,  True, False, False, False,  True,  True])\n    \n# Define a train function to be used in different threads\ndef train_fn(model, input):\n    # forward\n    y = model(input)\n    # backward\n    y.sum().backward()\n    # potential optimizer update\n\n# define your model in python or in TorchScript\nmodel = Model()\n# User write their own threading code to drive the train_fn\nthreads = []\nfor _ in range(10):\n    # define or load the data\n    input = torch.ones(5, 5, requires_grad=True)\n    p = threading.Thread(target=train_fn, args=(model, input))\n    p.start()\n    threads.append(p)\n\nfor p in threads:\n    p.join()\n\n# Define a train function to be used in different threads\ndef train_fn(model, input):\n    # forward\n    y = model(input)\n    # backward\n    y.sum().backward()\n    # potential optimizer update\n\n# define your model in python or in TorchScript\nmodel = Model()\n# User write their own threading code to drive the train_fn\nthreads = []\nfor _ in range(10):\n    # define or load the data\n    input = torch.ones(5, 5, requires_grad=True)\n    p = threading.Thread(target=train_fn, args=(model, input))\n    p.start()\n    threads.append(p)\n\nfor p in threads:\n    p.join()\n\nout = torch.add(a, b)\n\ntorch.add(a, b, out=out)"
            },
            {
                "code": "import torch\ntorch.manual_seed(1337)",
                "output": "# SobolEngine ignores the manual_seed and instead uses its own."
            },
            {
                "code": "import torch\n`x1 = SobolEngine(dimension=1, scramble=True, seed=None).draw(3)`",
                "output": ""
            },
            {
                "code": "import torch\ntorch.manual_seed(1337)",
                "output": "# SobolEngine ignores the manual_seed and instead uses its own."
            },
            {
                "code": "import torch\n`x1 = SobolEngine(dimension=1, scramble=True, seed=None).draw(3)`\nimport time",
                "output": ""
            },
            {
                "code": "import torch\ntorch.manual_seed(1337)",
                "output": "# To replicate the old behavior of, pass a seed to SobolEngine."
            },
            {
                "code": "import torch\nms_since_epoch = int(round(time.now() * 1000))",
                "output": ""
            },
            {
                "code": "import torch\nx1 = SobolEngine(dimension=1, scramble=True, seed=ms_since_epoch).draw(3)\nimport time",
                "output": ""
            },
            {
                "code": "import torch\ntorch.manual_seed(1337)",
                "output": "# To replicate the old behavior of, pass a seed to SobolEngine."
            },
            {
                "code": "import torch\nms_since_epoch = int(round(time.now() * 1000))",
                "output": ""
            },
            {
                "code": "import torch\nx1 = SobolEngine(dimension=1, scramble=True, seed=ms_since_epoch).draw(3)",
                "output": ""
            },
            {
                "code": "import torch\ntensor = torch.zeros(10, dtype=torch.uint8)\ntensor.random_(0, 257)",
                "output": "# 256 is the maximum value for `to` for `torch.uint8`\nUserWarning: to - 1 is out of bounds for unsigned char."
            },
            {
                "code": "import torch\ntensor = torch.zeros(10, dtype=torch.uint8)\ntensor.random_(0, 257)",
                "output": "# 256 is the maximum value for `to` for `torch.uint8`\nUserWarning: to - 1 is out of bounds for unsigned char."
            },
            {
                "code": "import torch\ntensor = torch.zeros(10, dtype=torch.uint8)\ntensor.random_(0, 256)",
                "output": "# 256 is the maximum value for `to` for `torch.uint8`"
            },
            {
                "code": "import torch\ntensor = torch.zeros(10, dtype=torch.uint8)\ntensor.random_(0, 256)",
                "output": "# 256 is the maximum value for `to` for `torch.uint8`\n    \n# v1.5\nrpc.init_rpc(\n    \"worker1\",\n    rank=0,\n    world_size=2,\n    rpc_backend_options=rpc.ProcessGroupRpcBackendOptions(\n        num_send_recv_threads=16,\n        datetime.timedelta(seconds=20)\n    )\n)\n\n# v1.5\nrpc.init_rpc(\n    \"worker1\",\n    rank=0,\n    world_size=2,\n    rpc_backend_options=rpc.ProcessGroupRpcBackendOptions(\n        num_send_recv_threads=16,\n        datetime.timedelta(seconds=20)\n    )\n)\n# v1.6\nrpc.init_rpc(\n    \"worker1\",\n    rank=0,\n    world_size=2,\n    rpc_backend_options=rpc.ProcessGroupRpcBackendOptions(\n        num_send_recv_threads=16,\n        20 # seconds\n    )\n)\n\n# v1.6\nrpc.init_rpc(\n    \"worker1\",\n    rank=0,\n    world_size=2,\n    rpc_backend_options=rpc.ProcessGroupRpcBackendOptions(\n        num_send_recv_threads=16,\n        20 # seconds\n    )\n)"
            },
            {
                "code": "import torch\ntorch.autograd.gradcheck(my_custom_function, inputs)",
                "output": "True"
            },
            {
                "code": "import torch\ntorch.autograd.gradcheck(my_custom_function, inputs)\n# To keep the previous behavior",
                "output": "True"
            },
            {
                "code": "import torch\ntorch.autograd.gradcheck(my_custom_function, inputs, check_undefined_grad=False)\n# To keep the previous behavior",
                "output": "True"
            },
            {
                "code": "import torch\ntorch.autograd.gradcheck(my_custom_function, inputs, check_undefined_grad=False)",
                "output": "True\n    \n\nm = MyMod()\ntorch.save(m.state_dict(), 'mymod.pt') # Saves a zipfile to mymod.pt\n\nm = MyMod()\ntorch.save(m.state_dict(), 'mymod.pt', _use_new_zipfile_serialization=False) # Saves pickle\nstatic auto registry =\n  torch::RegisterOperators(\"my_ops::warp_perspective\", &warp_perspective);\n\nstatic auto registry =\n  torch::RegisterOperators(\"my_ops::warp_perspective\", &warp_perspective);\nTORCH_LIBRARY(my_ops, m) {\n  m.def(\"warp_perspective\", warp_perspective);\n}\n\nTORCH_LIBRARY(my_ops, m) {\n  m.def(\"warp_perspective\", warp_perspective);\n}"
            }
        ],
        "examples_count": 52,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.6.0",
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/torch.html#torch.abs",
        "api": "torch.abs",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Unifying function names for consistency and clarity.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.zeros(1, requires_grad=True)",
                "output": ""
            },
            {
                "code": "with torch.no_grad():\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "is_train = False",
                "output": ""
            },
            {
                "code": "with torch.set_grad_enabled(is_train):\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "torch.set_grad_enabled(True)  # this can also be used as a function",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "True"
            },
            {
                "code": "torch.set_grad_enabled(False)",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "False"
            }
        ],
        "examples_count": 8,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.arccos.html",
        "api": "torch.arccos",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "torch.arccos is aliased to torch.acos for consistency. Users are encouraged to use the standard API name, torch.acos.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8.0",
        "removed_in": "3.0.0",
        "replaced_by": "torch.acos"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.angle.html",
        "api": "torch.angle",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "The behavior was updated to conform to mathematical conventions and provide accurate propagation of NaNs.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.angle(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))*180/3.14159",
                "output": "tensor([ 135.,  135,  -45])"
            }
        ],
        "examples_count": 1,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.asin",
        "api": "torch.asin",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The naming convention changed to align better with mathematical terminology.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(4)\na",
                "output": "tensor([-0.5962,  1.4985, -0.4396,  1.4525])"
            },
            {
                "code": "torch.asin(a)",
                "output": "tensor([-0.6387,     nan, -0.4552,     nan])"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.arccosh.html",
        "api": "torch.arccosh",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The function 'torch.arccosh' serves as an alias for 'torch.acosh()' to maintain consistency with naming conventions in mathematical libraries. Explicit encouragement to use 'torch.acosh' ensures reduced ambiguity and better alignment with common standards.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.7",
        "removed_in": "2.9",
        "replaced_by": "torch.acosh"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.arctanh.html",
        "api": "torch.arctanh",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The alias `torch.arctanh` is deprecated to reduce redundancy, as similar functionality is available via `torch.atanh`.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.7",
        "removed_in": "2.9",
        "replaced_by": "torch.atanh"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/torch.html#torch.arctan",
        "api": "torch.arctan",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The alias 'torch.arctan' was introduced for compatibility, but users are encouraged to use 'torch.atan' for consistency with other trigonometric functions.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.zeros(1, requires_grad=True)",
                "output": ""
            },
            {
                "code": "with torch.no_grad():\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "is_train = False",
                "output": ""
            },
            {
                "code": "with torch.set_grad_enabled(is_train):\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "torch.set_grad_enabled(True)  # this can also be used as a function",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "True"
            },
            {
                "code": "torch.set_grad_enabled(False)",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "False"
            }
        ],
        "examples_count": 8,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "3.0",
        "replaced_by": "torch.atan"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.clip.html",
        "api": "torch.clip",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Alias for torch.clamp() to provide clearer naming and ensure consistency across the API.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.clamp"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.clamp.html",
        "api": "torch.clamp",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The introduction of `torch.clip` provides a more universally understood function name across libraries and frameworks. `torch.clamp` remains functional for compatibility.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(4)\na",
                "output": "tensor([-1.7120,  0.1734, -0.0478, -0.0922])"
            },
            {
                "code": "torch.clamp(a, min=-0.5, max=0.5)",
                "output": "tensor([-0.5000,  0.1734, -0.0478, -0.0922])"
            },
            {
                "code": "min = torch.linspace(-1, 1, steps=4)",
                "output": ""
            },
            {
                "code": "torch.clamp(a, min=min)",
                "output": "tensor([-1.0000,  0.1734,  0.3333,  1.0000])"
            }
        ],
        "examples_count": 4,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.clip"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.erf.html",
        "api": "torch.erf",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The functionality of `torch.erf` is being transitioned to `torch.special.erf` to consolidate mathematical operations under a unified namespace (`torch.special`).",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.6",
        "removed_in": "2.8",
        "replaced_by": "torch.special.erf"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.divide.html",
        "api": "torch.divide",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The torch.divide function was designated as an alias for torch.div to maintain consistency across PyTorch and simplify the API.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": null,
        "replaced_by": "torch.div"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.digamma.html",
        "api": "torch.digamma",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "To ensure consistency and clarity in API usage by consolidating specialized mathematical functions under the `torch.special` module.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": null,
        "replaced_by": "torch.special.digamma"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.erfc.html",
        "api": "torch.erfc",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The `torch.erfc` API was aliased to `torch.special.erfc()` for better organization and to group special functions logically under a dedicated namespace.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": null,
        "replaced_by": "torch.special.erfc"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.erfinv.html",
        "api": "torch.erfinv",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Simplification and consolidation of mathematical operations under `torch.special` namespace to improve API clarity.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.expm1.html",
        "api": "torch.expm1",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Unified under torch.special namespace for mathematical functions to improve consistency and organization.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": null,
        "replaced_by": "torch.special.expm1"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.fix.html",
        "api": "torch.fix",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "torch.fix was re-aliased to torch.trunc for consistency in functionality, as both perform truncation of input values.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.trunc"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.floor_divide.html",
        "api": "torch.floor_divide",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "The original implementation of `torch.floor_divide` incorrectly performed truncation division instead of floor division.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor([4.0, 3.0])",
                "output": ""
            },
            {
                "code": "b = torch.tensor([2.0, 2.0])",
                "output": ""
            },
            {
                "code": "torch.floor_divide(a, b)",
                "output": "tensor([2.0, 1.0])"
            },
            {
                "code": "torch.floor_divide(a, 1.4)",
                "output": "tensor([2.0, 2.0])"
            }
        ],
        "examples_count": 4,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.9.0",
        "removed_in": null,
        "replaced_by": "torch.div(..., rounding_mode='floor')"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.special.i0.html",
        "api": "torch.i0",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Consolidation of functionality into the `torch.special` namespace for better organization and alignment with mathematical operations.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": null,
        "replaced_by": "torch.special.i0"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.igammac.html",
        "api": "torch.igammac",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Introduced as an alias to the existing `torch.special.gammaincc()` for clarity and uniform usage across the library.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.special.gammaincc"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.logit.html",
        "api": "torch.logit",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The function was simplified to alias the equivalent `torch.special.logit` function for better consistency across PyTorch special functions.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": null,
        "replaced_by": "torch.special.logit"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.multiply.html",
        "api": "torch.multiply",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The alias `torch.multiply` was introduced for user convenience but is internally equivalent to `torch.mul`. The change encourages users to adopt the canonical API name for consistency and maintainability across PyTorch versions.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.mul"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.igamma.html",
        "api": "torch.igamma",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The function `torch.igamma` was deprecated and replaced for better alignment with established naming conventions used in other libraries and frameworks. The new name, `torch.special.gammainc`, is consistent with standard mathematical terminology.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": "3.0",
        "replaced_by": "torch.special.gammainc"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.mvlgamma.html",
        "api": "torch.mvlgamma",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The API alias was replaced by its canonical name to improve consistency and clarity for users.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.negative.html",
        "api": "torch.neg",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The `torch.negative` API was introduced as a more descriptive alternative to `torch.neg`, aligning with best practices for API naming and consistency.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.negative"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html",
        "api": "torch.softmax",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Streamlining API behavior and encouraging the use of functional-style APIs.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.sinc.html",
        "api": "torch.sinc",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Standardization and consolidation of special mathematical functions under the 'torch.special' namespace.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.7",
        "removed_in": "3.0",
        "replaced_by": "torch.special.sinc"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.sigmoid.html",
        "api": "torch.sigmoid",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "To align with a more standardized mathematical function name and improve consistency across PyTorch's API.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "0.4.0",
        "removed_in": "1.0.0",
        "replaced_by": "torch.sigmoid"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.sub.html",
        "api": "torch.sub",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Unification with similar function names in the PyTorch library for consistency and readability.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor((1, 2))",
                "output": ""
            },
            {
                "code": "b = torch.tensor((0, 1))",
                "output": ""
            },
            {
                "code": "torch.sub(a, b, alpha=2)",
                "output": "tensor([1, 0])"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/torch.subtract.html",
        "api": "torch.subtract",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "torch.subtract is an alias for torch.sub. It is maintained for historical reasons to ensure backward compatibility, but torch.sub is the preferred usage.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.sub"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.true_divide.html",
        "api": "torch.true_divide",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "To simplify and standardize API usage, consolidating multiple methods into a single call `torch.div` with an explicit `rounding_mode` parameter.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.7",
        "removed_in": null,
        "replaced_by": "torch.div with rounding_mode=None"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.xlogy.html",
        "api": "torch.xlogy",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Unified function aliasing under the `torch.special` module for better consistency and clarity.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.0.0",
        "removed_in": "2.2.0",
        "replaced_by": "torch.special.xlogy"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.min.html",
        "api": "torch.min",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The `torch.min(input, other, *, out=None)` signature was marked as deprecated to consolidate usage and guide users towards `torch.minimum` for clarity.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(1, 3)\na",
                "output": "tensor([[ 0.6750,  1.0857,  1.7197]])"
            },
            {
                "code": "torch.min(a)",
                "output": "tensor(0.6750)"
            },
            {
                "code": "a = torch.randn(4, 4)\na",
                "output": "tensor([[-0.6248,  1.1334, -1.1899, -0.2803],\n        [-1.4644, -0.2635, -0.3651,  0.6134],\n        [ 0.2457,  0.0384,  1.0128,  0.7015],\n        [-0.1153,  2.9849,  2.1458,  0.5788]])"
            },
            {
                "code": "torch.min(a, 1)",
                "output": "torch.return_types.min(values=tensor([-1.1899, -1.4644,  0.0384, -0.1153]), indices=tensor([2, 0, 1, 0]))"
            },
            {
                "code": "a = torch.randn(4, 4)\na",
                "output": "tensor([[-0.6248,  1.1334, -1.1899, -0.2803],\n        [-1.4644, -0.2635, -0.3651,  0.6134],\n        [ 0.2457,  0.0384,  1.0128,  0.7015],\n        [-0.1153,  2.9849,  2.1458,  0.5788]])"
            },
            {
                "code": "torch.min(a, 1)",
                "output": "torch.return_types.min(values=tensor([-1.1899, -1.4644,  0.0384, -0.1153]), indices=tensor([2, 0, 1, 0]))"
            }
        ],
        "examples_count": 6,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": null,
        "replaced_by": "torch.minimum"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.max.html",
        "api": "torch.max",
        "package": "PyTorch",
        "change_type": "",
        "reason": "",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(1, 3)\na",
                "output": "tensor([[ 0.6763,  0.7445, -2.2369]])"
            },
            {
                "code": "torch.max(a)",
                "output": "tensor(0.7445)"
            },
            {
                "code": "a = torch.randn(4, 4)\na",
                "output": "tensor([[-1.2360, -0.2942, -0.1222,  0.8475],\n        [ 1.1949, -1.1127, -2.2379, -0.6702],\n        [ 1.5717, -0.9207,  0.1297, -1.8768],\n        [-0.6172,  1.0036, -0.6060, -0.2432]])"
            },
            {
                "code": "torch.max(a, 1)",
                "output": "torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))"
            },
            {
                "code": "a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])",
                "output": ""
            },
            {
                "code": "a.max(dim=1, keepdim=True)",
                "output": "torch.return_types.max(\nvalues=tensor([[2.], [4.]]),\nindices=tensor([[1], [1]]))"
            },
            {
                "code": "a.max(dim=1, keepdim=False)",
                "output": "torch.return_types.max(\nvalues=tensor([2., 4.]),\nindices=tensor([1, 1]))"
            },
            {
                "code": "a = torch.randn(4, 4)\na",
                "output": "tensor([[-1.2360, -0.2942, -0.1222,  0.8475],\n        [ 1.1949, -1.1127, -2.2379, -0.6702],\n        [ 1.5717, -0.9207,  0.1297, -1.8768],\n        [-0.6172,  1.0036, -0.6060, -0.2432]])"
            },
            {
                "code": "torch.max(a, 1)",
                "output": "torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))"
            },
            {
                "code": "a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])",
                "output": ""
            },
            {
                "code": "a.max(dim=1, keepdim=True)",
                "output": "torch.return_types.max(\nvalues=tensor([[2.], [4.]]),\nindices=tensor([[1], [1]]))"
            },
            {
                "code": "a.max(dim=1, keepdim=False)",
                "output": "torch.return_types.max(\nvalues=tensor([2., 4.]),\nindices=tensor([1, 1]))"
            }
        ],
        "examples_count": 12,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.median.html",
        "api": "torch.median",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "In cases where the input tensor has an even number of elements, torch.median returns the lower of the two medians, which may differ from expectations. Users requiring the mean of both medians should use torch.quantile(q=0.5).",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(1, 3)\na",
                "output": "tensor([[ 1.5219, -1.5212,  0.2202]])"
            },
            {
                "code": "torch.median(a)",
                "output": "tensor(0.2202)"
            },
            {
                "code": "a = torch.randn(4, 5)\na",
                "output": "tensor([[ 0.2505, -0.3982, -0.9948,  0.3518, -1.3131],\n        [ 0.3180, -0.6993,  1.0436,  0.0438,  0.2270],\n        [-0.2751,  0.7303,  0.2192,  0.3321,  0.2488],\n        [ 1.0778, -1.9510,  0.7048,  0.4742, -0.7125]])"
            },
            {
                "code": "torch.median(a, 1)",
                "output": "torch.return_types.median(values=tensor([-0.3982,  0.2270,  0.2488,  0.4742]), indices=tensor([1, 4, 4, 3]))"
            },
            {
                "code": "a = torch.randn(4, 5)\na",
                "output": "tensor([[ 0.2505, -0.3982, -0.9948,  0.3518, -1.3131],\n        [ 0.3180, -0.6993,  1.0436,  0.0438,  0.2270],\n        [-0.2751,  0.7303,  0.2192,  0.3321,  0.2488],\n        [ 1.0778, -1.9510,  0.7048,  0.4742, -0.7125]])"
            },
            {
                "code": "torch.median(a, 1)",
                "output": "torch.return_types.median(values=tensor([-0.3982,  0.2270,  0.2488,  0.4742]), indices=tensor([1, 4, 4, 3]))"
            }
        ],
        "examples_count": 6,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.quantile(q=0.5)"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.norm.html",
        "api": "torch.norm",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Deprecated due to inaccuracies in documentation and behavior, and lack of active maintenance. Alternatives offer more precise and flexible functionality.",
        "has_examples": true,
        "examples": [
            {
                "code": "import torch\na = torch.arange(9, dtype= torch.float) - 4",
                "output": ""
            },
            {
                "code": "import torch\nb = a.reshape((3, 3))",
                "output": ""
            },
            {
                "code": "import torch\ntorch.norm(a)",
                "output": "tensor(7.7460)"
            },
            {
                "code": "import torch\ntorch.norm(b)",
                "output": "tensor(7.7460)"
            },
            {
                "code": "import torch\ntorch.norm(a, float('inf'))",
                "output": "tensor(4.)"
            },
            {
                "code": "import torch\ntorch.norm(b, float('inf'))",
                "output": "tensor(4.)"
            },
            {
                "code": "import torch\nc = torch.tensor([[ 1, 2, 3], [-1, 1, 4]] , dtype=torch.float)",
                "output": ""
            },
            {
                "code": "import torch\ntorch.norm(c, dim=0)",
                "output": "tensor([1.4142, 2.2361, 5.0000])"
            },
            {
                "code": "import torch\ntorch.norm(c, dim=1)",
                "output": "tensor([3.7417, 4.2426])"
            },
            {
                "code": "import torch\ntorch.norm(c, p=1, dim=1)",
                "output": "tensor([6., 6.])"
            },
            {
                "code": "import torch\nd = torch.arange(8, dtype=torch.float).reshape(2, 2, 2)",
                "output": ""
            },
            {
                "code": "import torch\ntorch.norm(d, dim=(1, 2))",
                "output": "tensor([ 3.7417, 11.2250])"
            },
            {
                "code": "import torch\ntorch.norm(d[0, :, :]), torch.norm(d[1, :, :])",
                "output": "(tensor(3.7417), tensor(11.2250))"
            }
        ],
        "examples_count": 13,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "2.10",
        "replaced_by": [
            "torch.linalg.vector_norm",
            "torch.linalg.matrix_norm",
            "torch.linalg.norm"
        ]
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.std_mean.html",
        "api": "torch.std_mean",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "The 'unbiased' parameter was renamed to 'correction' for improved clarity and flexibility, allowing integer values instead of a boolean type.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor(\n[[ 0.2035,  1.2959,  1.8101, -0.4644],\n[ 1.5027, -0.3270,  0.5905,  0.6538],\n[-1.5745,  1.3330, -0.5596, -0.6548],\n[ 0.1264, -0.5080,  1.6420,  0.1992]]\n)  # fmt: skip",
                "output": ""
            },
            {
                "code": "torch.std_mean(a, dim=0, keepdim=True)",
                "output": "(tensor([[1.2620, 1.0028, 1.0957, 0.6038]]),\n tensor([[ 0.0645,  0.4485,  0.8707, -0.0665]]))"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.0",
        "removed_in": null,
        "replaced_by": "correction"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.std.html",
        "api": "torch.std",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "The 'unbiased' parameter was renamed to 'correction' to improve clarity and align its functionality more explicitly with Bessel’s correction, where `correction=1` corresponds to the previous `unbiased=True` and `correction=0` corresponds to `unbiased=False`.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor(\n[[ 0.2035,  1.2959,  1.8101, -0.4644],\n[ 1.5027, -0.3270,  0.5905,  0.6538],\n[-1.5745,  1.3330, -0.5596, -0.6548],\n[ 0.1264, -0.5080,  1.6420,  0.1992]]\n)  # fmt: skip",
                "output": ""
            },
            {
                "code": "torch.std(a, dim=1, keepdim=True)",
                "output": "tensor([[1.0311],\n        [0.7477],\n        [1.2204],\n        [0.9087]])"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.0",
        "removed_in": null,
        "replaced_by": "correction"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.var.html",
        "api": "torch.var",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "The `unbiased` argument was renamed to `correction` for clarity and flexibility. The updated `correction` parameter allows specifying the difference between the sample size and sample degrees of freedom.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor(\n[[ 0.2035,  1.2959,  1.8101, -0.4644],\n[ 1.5027, -0.3270,  0.5905,  0.6538],\n[-1.5745,  1.3330, -0.5596, -0.6548],\n[ 0.1264, -0.5080,  1.6420,  0.1992]]\n)  # fmt: skip",
                "output": ""
            },
            {
                "code": "torch.var(a, dim=1, keepdim=True)",
                "output": "tensor([[1.0631],\n        [0.5590],\n        [1.4893],\n        [0.8258]])"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.0",
        "removed_in": null,
        "replaced_by": "correction"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.var_mean.html",
        "api": "torch.var_mean",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "The `unbiased` parameter was replaced with the `correction` parameter for more explicit control over the variance calculation. This also aligns the API naming conventions to industry standards.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor(\n[[ 0.2035,  1.2959,  1.8101, -0.4644],\n[ 1.5027, -0.3270,  0.5905,  0.6538],\n[-1.5745,  1.3330, -0.5596, -0.6548],\n[ 0.1264, -0.5080,  1.6420,  0.1992]]\n)  # fmt: skip",
                "output": ""
            },
            {
                "code": "torch.var_mean(a, dim=0, keepdim=True)",
                "output": "(tensor([[1.5926, 1.0056, 1.2005, 0.3646]]),\n tensor([[ 0.0645,  0.4485,  0.8707, -0.0665]]))"
            }
        ],
        "examples_count": 2,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.0",
        "removed_in": null,
        "replaced_by": "correction"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.greater_equal.html",
        "api": "torch.greater_equal",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Alias for torch.ge() to align API functionality consistently across versions.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.ge"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/torch.html#torch.greater",
        "api": "torch.greater",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Alias for torch.gt. No functional difference; streamlined documentation to reduce redundancy.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.zeros(1, requires_grad=True)",
                "output": ""
            },
            {
                "code": "with torch.no_grad():\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "is_train = False",
                "output": ""
            },
            {
                "code": "with torch.set_grad_enabled(is_train):\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "torch.set_grad_enabled(True)  # this can also be used as a function",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "True"
            },
            {
                "code": "torch.set_grad_enabled(False)",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "False"
            }
        ],
        "examples_count": 8,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "2.10",
        "replaced_by": "torch.gt"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.le.html",
        "api": "torch.le",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Standardizing API naming conventions for consistency and readability.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.le(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))",
                "output": "tensor([[True, False], [True, True]])"
            }
        ],
        "examples_count": 1,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.less.html",
        "api": "torch.less",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The API name was unified to align with consistent naming conventions across PyTorch.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.0",
        "removed_in": "2.2",
        "replaced_by": "torch.lt"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/",
        "api": "torch.msort",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Redundant functionality—torch.msort has the same behavior as torch.sort(input, dim=0)[0]. To streamline the API, it was marked for deprecation.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "2.9",
        "replaced_by": "torch.sort(input, dim=0)[0]"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.fmin.html",
        "api": "torch.fmin",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "torch.fmin was introduced to handle NaNs differently compared to torch.minimum—making the non-NaN element the minimum in cases where one of the elements is NaN.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor([2.2, float('nan'), 2.1, float('nan')])",
                "output": ""
            },
            {
                "code": "b = torch.tensor([-9.3, 0.1, float('nan'), float('nan')])",
                "output": ""
            },
            {
                "code": "torch.fmin(a, b)",
                "output": "tensor([-9.3000, 0.1000, 2.1000,    nan])"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.ne.html",
        "api": "torch.ne",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The API `torch.ne` has been replaced by `torch.not_equal` to maintain consistency in naming conventions.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.ne(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))",
                "output": "tensor([[False, True], [True, False]])"
            }
        ],
        "examples_count": 1,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.not_equal.html",
        "api": "torch.not_equal",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The `torch.not_equal` is an alias of `torch.ne()`, simplifying the interface by recommending a single, canonical name (`torch.ne`).",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.7",
        "removed_in": "2.9",
        "replaced_by": "torch.ne"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.stft.html",
        "api": "torch.stft",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "The parameter `return_complex` must now be explicitly specified for real inputs. Strong preference for `return_complex=True` has been recommended. Additionally, the behavior of `window` will require explicit specification from version 2.1 to avoid potential artifacts.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "1.8.0",
        "removed_in": "2.0.0",
        "replaced_by": "return_complex=True"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.istft.html",
        "api": "torch.istft",
        "package": "PyTorch",
        "change_type": "Parameter Change",
        "reason": "From version 2.1, a warning is issued if the 'window' parameter is not specified. In a future release, this parameter will be mandatory to ensure accurate reconstruction of the signal from the STFT.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.1",
        "removed_in": null,
        "replaced_by": null
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.cross.html",
        "api": "torch.cross",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The default `dim` behavior in `torch.cross` (automatically selecting the first dimension with size 3) is considered unexpected. Moving to `torch.linalg.cross`, which uses `dim=-1` by default, makes the API more consistent and intuitive.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(4, 3)\na",
                "output": "tensor([[-0.3956,  1.1455,  1.6895],\n        [-0.5849,  1.3672,  0.3599],\n        [-1.1626,  0.7180, -0.0521],\n        [-0.1339,  0.9902, -2.0225]])"
            },
            {
                "code": "b = torch.randn(4, 3)\nb",
                "output": "tensor([[-0.0257, -1.4725, -1.2251],\n        [-1.1479, -0.7005, -1.9757],\n        [-1.3904,  0.3726, -1.1836],\n        [-0.9688, -0.7153,  0.2159]])"
            },
            {
                "code": "torch.cross(a, b, dim=1)",
                "output": "tensor([[ 1.0844, -0.5281,  0.6120],\n        [-2.4490, -1.5687,  1.9792],\n        [-0.8304, -1.3037,  0.5650],\n        [-1.2329,  1.9883,  1.0551]])"
            },
            {
                "code": "torch.cross(a, b)",
                "output": "tensor([[ 1.0844, -0.5281,  0.6120],\n        [-2.4490, -1.5687,  1.9792],\n        [-0.8304, -1.3037,  0.5650],\n        [-1.2329,  1.9883,  1.0551]])"
            }
        ],
        "examples_count": 4,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.11.0",
        "removed_in": "2.0.0",
        "replaced_by": "torch.linalg.cross"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.histc.html",
        "api": "torch.histc",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Providing greater flexibility and more advanced functionality with `torch.histogram`.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.histc(torch.tensor([1., 2, 1]), bins=4, min=0, max=3)",
                "output": "tensor([ 0.,  2.,  1.,  0.])"
            }
        ],
        "examples_count": 1,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.6",
        "removed_in": "2.9",
        "replaced_by": "torch.histogram"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.chain_matmul.html",
        "api": "torch.chain_matmul",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "To promote the use of the more flexible and efficient `torch.linalg.multi_dot`, which can handle lists of tensors and supports future optimizations.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(3, 4)",
                "output": ""
            },
            {
                "code": "b = torch.randn(4, 5)",
                "output": ""
            },
            {
                "code": "c = torch.randn(5, 6)",
                "output": ""
            },
            {
                "code": "d = torch.randn(6, 7)\n# will raise a deprecation warning",
                "output": ""
            },
            {
                "code": "torch.chain_matmul(a, b, c, d)",
                "output": "tensor([[ -2.3375,  -3.9790,  -4.1119,  -6.6577,   9.5609, -11.5095,  -3.2614],\n        [ 21.4038,   3.3378,  -8.4982,  -5.2457, -10.2561,  -2.4684,   2.7163],\n        [ -0.9647,  -5.8917,  -2.3213,  -5.2284,  12.8615, -12.2816,  -2.5095]])"
            }
        ],
        "examples_count": 5,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "TBD",
        "replaced_by": "torch.linalg.multi_dot"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.cholesky.html",
        "api": "torch.cholesky",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Consolidation of linear algebra functions under the torch.linalg namespace for better organization and alignment with NumPy.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(3, 3)",
                "output": "L = torch.linalg.cholesky(A)\n\n\nU = torch.linalg.cholesky(A).mH"
            },
            {
                "code": "a = a @ a.mT + 1e-3 # make symmetric positive-definite",
                "output": ""
            },
            {
                "code": "l = torch.cholesky(a)\na\nl\nl @ l.mT",
                "output": "tensor([[ 2.4112, -0.7486,  1.4551],\n        [-0.7486,  1.3544,  0.1294],\n        [ 1.4551,  0.1294,  1.6724]])\ntensor([[ 1.5528,  0.0000,  0.0000],\n        [-0.4821,  1.0592,  0.0000],\n        [ 0.9371,  0.5487,  0.7023]])\ntensor([[ 2.4112, -0.7486,  1.4551],\n        [-0.7486,  1.3544,  0.1294],\n        [ 1.4551,  0.1294,  1.6724]])"
            },
            {
                "code": "a = torch.randn(3, 2, 2) # Example for batched input",
                "output": ""
            },
            {
                "code": "a = a @ a.mT + 1e-03 # make symmetric positive-definite",
                "output": ""
            },
            {
                "code": "l = torch.cholesky(a)",
                "output": ""
            },
            {
                "code": "z = l @ l.mT",
                "output": ""
            },
            {
                "code": "torch.dist(z, a)",
                "output": "tensor(2.3842e-07)"
            },
            {
                "code": "a = torch.randn(3, 3)",
                "output": ""
            },
            {
                "code": "a = a @ a.mT + 1e-3 # make symmetric positive-definite",
                "output": ""
            },
            {
                "code": "l = torch.cholesky(a)\na\nl\nl @ l.mT",
                "output": "tensor([[ 2.4112, -0.7486,  1.4551],\n        [-0.7486,  1.3544,  0.1294],\n        [ 1.4551,  0.1294,  1.6724]])\ntensor([[ 1.5528,  0.0000,  0.0000],\n        [-0.4821,  1.0592,  0.0000],\n        [ 0.9371,  0.5487,  0.7023]])\ntensor([[ 2.4112, -0.7486,  1.4551],\n        [-0.7486,  1.3544,  0.1294],\n        [ 1.4551,  0.1294,  1.6724]])"
            },
            {
                "code": "a = torch.randn(3, 2, 2) # Example for batched input",
                "output": ""
            },
            {
                "code": "a = a @ a.mT + 1e-03 # make symmetric positive-definite",
                "output": ""
            },
            {
                "code": "l = torch.cholesky(a)",
                "output": ""
            },
            {
                "code": "z = l @ l.mT",
                "output": ""
            },
            {
                "code": "torch.dist(z, a)",
                "output": "tensor(2.3842e-07)"
            }
        ],
        "examples_count": 16,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.9.0",
        "removed_in": "2.0.0",
        "replaced_by": "torch.linalg.cholesky"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.cholesky_inverse.html",
        "api": "torch.cholesky_inverse",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Unified decomposition-based APIs in the `torch.linalg` namespace for clarity and modernization.",
        "has_examples": true,
        "examples": [
            {
                "code": "A = torch.randn(3, 3)",
                "output": ""
            },
            {
                "code": "A = A @ A.T + torch.eye(3) * 1e-3 # Creates a symmetric positive-definite matrix",
                "output": ""
            },
            {
                "code": "L = torch.linalg.cholesky(A) # Extract Cholesky decomposition",
                "output": ""
            },
            {
                "code": "torch.cholesky_inverse(L)\nA.inverse()",
                "output": "tensor([[ 1.9314,  1.2251, -0.0889],\n        [ 1.2251,  2.4439,  0.2122],\n        [-0.0889,  0.2122,  0.1412]])\ntensor([[ 1.9314,  1.2251, -0.0889],\n        [ 1.2251,  2.4439,  0.2122],\n        [-0.0889,  0.2122,  0.1412]])"
            },
            {
                "code": "A = torch.randn(3, 2, 2, dtype=torch.complex64)",
                "output": ""
            },
            {
                "code": "A = A @ A.mH + torch.eye(2) * 1e-3 # Batch of Hermitian positive-definite matrices",
                "output": ""
            },
            {
                "code": "L = torch.linalg.cholesky(A)",
                "output": ""
            },
            {
                "code": "torch.dist(torch.inverse(A), torch.cholesky_inverse(L))",
                "output": "tensor(5.6358e-7)"
            }
        ],
        "examples_count": 8,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.9.0",
        "removed_in": "2.0.0",
        "replaced_by": "torch.linalg.cholesky_inverse"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/torch.geqrf.html",
        "api": "torch.geqrf",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The new `torch.linalg.qr` function provides a more comprehensive and explicit way to compute the QR decomposition, including directly returning Q and R matrices, which modernizes and simplifies its usage.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": null,
        "replaced_by": "torch.linalg.qr"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/torch.html#torch.outer",
        "api": "torch.ger",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The `torch.ger` function duplicates the functionality of `torch.outer` and is streamlined for API consistency.",
        "has_examples": true,
        "examples": [
            {
                "code": "x = torch.zeros(1, requires_grad=True)",
                "output": ""
            },
            {
                "code": "with torch.no_grad():\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "is_train = False",
                "output": ""
            },
            {
                "code": "with torch.set_grad_enabled(is_train):\ny = x * 2\ny.requires_grad",
                "output": "False"
            },
            {
                "code": "torch.set_grad_enabled(True)  # this can also be used as a function",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "True"
            },
            {
                "code": "torch.set_grad_enabled(False)",
                "output": ""
            },
            {
                "code": "y = x * 2\ny.requires_grad",
                "output": "False"
            }
        ],
        "examples_count": 8,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": "TBD",
        "replaced_by": "torch.outer"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.inverse.html",
        "api": "torch.inverse",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The functionality of `torch.inverse` has been consolidated under the `torch.linalg` namespace to improve modularity and consistency in linear algebra operations.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "1.9.0",
        "removed_in": null,
        "replaced_by": "torch.linalg.inverse"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.linalg.det.html",
        "api": "torch.det",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The function `torch.det` was moved under `torch.linalg` to reorganize linear algebra functions for better clarity and consistency.",
        "has_examples": true,
        "examples": [
            {
                "code": "A = torch.randn(3, 3)",
                "output": ""
            },
            {
                "code": "torch.linalg.det(A)",
                "output": "tensor(0.0934)"
            },
            {
                "code": "A = torch.randn(3, 2, 2)",
                "output": ""
            },
            {
                "code": "torch.linalg.det(A)",
                "output": "tensor([1.1990, 0.4099, 0.7386])"
            }
        ],
        "examples_count": 4,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.9.0",
        "removed_in": null,
        "replaced_by": "torch.linalg.det"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.linalg.slogdet.html",
        "api": "torch.slogdet",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Consolidation and migration to the `torch.linalg` namespace for improved organization and consistency of linear algebra functionalities.",
        "has_examples": true,
        "examples": [
            {
                "code": "A = torch.randn(3, 3)\nA",
                "output": "tensor([[ 0.0032, -0.2239, -1.1219],\n        [-0.6690,  0.1161,  0.4053],\n        [-1.6218, -0.9273, -0.0082]])"
            },
            {
                "code": "torch.linalg.det(A)",
                "output": "tensor(-0.7576)"
            },
            {
                "code": "torch.logdet(A)",
                "output": "tensor(nan)"
            },
            {
                "code": "torch.linalg.slogdet(A)",
                "output": "torch.return_types.linalg_slogdet(sign=tensor(-1.), logabsdet=tensor(-0.2776))"
            }
        ],
        "examples_count": 4,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.8.0",
        "removed_in": null,
        "replaced_by": "torch.linalg.slogdet"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.logdet.html",
        "api": "torch.logdet",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Improved API functionality provided by `torch.linalg.slogdet`, which calculates both the sign and log of the determinant, offering better functionality and reliability compared to `torch.logdet`.",
        "has_examples": true,
        "examples": [
            {
                "code": "A = torch.randn(3, 3)",
                "output": ""
            },
            {
                "code": "torch.det(A)",
                "output": "tensor(0.2611)"
            },
            {
                "code": "torch.logdet(A)\nA\nA.det()\nA.det().log()",
                "output": "tensor(-1.3430)\ntensor([[[ 0.9254, -0.6213],\n         [-0.5787,  1.6843]],\n\n        [[ 0.3242, -0.9665],\n         [ 0.4539, -0.0887]],\n\n        [[ 1.1336, -0.4025],\n         [-0.7089,  0.9032]]])\ntensor([1.1990, 0.4099, 0.7386])\ntensor([ 0.1815, -0.8917, -0.3031])"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.9.0",
        "removed_in": null,
        "replaced_by": "torch.linalg.slogdet"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.lu.html",
        "api": "torch.lu",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Deprecation of torch.lu aligns PyTorch APIs to use linalg modules for matrix factorization, offering expanded functionality, better design consistency, and precision improvements.",
        "has_examples": true,
        "examples": [
            {
                "code": "A = torch.randn(2, 3, 3)",
                "output": "LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n\nLU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots)\n\n\nLU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots)"
            },
            {
                "code": "A_LU, pivots = torch.lu(A)\nA_LU\npivots",
                "output": "tensor([[[ 1.3506,  2.5558, -0.0816],\n         [ 0.1684,  1.1551,  0.1940],\n         [ 0.1193,  0.6189, -0.5497]],\n\n        [[ 0.4526,  1.2526, -0.3285],\n         [-0.7988,  0.7175, -0.9701],\n         [ 0.2634, -0.9255, -0.3459]]])\ntensor([[ 3,  3,  3],\n        [ 3,  3,  3]], dtype=torch.int32)"
            },
            {
                "code": "A_LU, pivots, info = torch.lu(A, get_infos=True)",
                "output": ""
            },
            {
                "code": "if info.nonzero().size(0) == 0:\nprint('LU factorization succeeded for all samples!')",
                "output": "LU factorization succeeded for all samples!"
            },
            {
                "code": "A = torch.randn(2, 3, 3)",
                "output": ""
            },
            {
                "code": "A_LU, pivots = torch.lu(A)\nA_LU\npivots",
                "output": "tensor([[[ 1.3506,  2.5558, -0.0816],\n         [ 0.1684,  1.1551,  0.1940],\n         [ 0.1193,  0.6189, -0.5497]],\n\n        [[ 0.4526,  1.2526, -0.3285],\n         [-0.7988,  0.7175, -0.9701],\n         [ 0.2634, -0.9255, -0.3459]]])\ntensor([[ 3,  3,  3],\n        [ 3,  3,  3]], dtype=torch.int32)"
            },
            {
                "code": "A_LU, pivots, info = torch.lu(A, get_infos=True)",
                "output": ""
            },
            {
                "code": "if info.nonzero().size(0) == 0:\nprint('LU factorization succeeded for all samples!')",
                "output": "LU factorization succeeded for all samples!"
            }
        ],
        "examples_count": 8,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.9",
        "removed_in": "3.0",
        "replaced_by": "torch.linalg.lu_factor"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html",
        "api": "torch.lu_solve",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "torch.lu_solve() is deprecated in favor of torch.linalg.lu_solve(). The new API is part of the torch.linalg module and adheres to the design principles of newer linear algebra functions.",
        "has_examples": true,
        "examples": [
            {
                "code": "A = torch.randn(2, 3, 3)",
                "output": "X = linalg.lu_solve(LU, pivots, B)"
            },
            {
                "code": "b = torch.randn(2, 3, 1)",
                "output": ""
            },
            {
                "code": "LU, pivots = torch.linalg.lu_factor(A)",
                "output": ""
            },
            {
                "code": "x = torch.lu_solve(b, LU, pivots)",
                "output": ""
            },
            {
                "code": "torch.dist(A @ x, b)",
                "output": "tensor(1.00000e-07 *\n       2.8312)"
            },
            {
                "code": "A = torch.randn(2, 3, 3)",
                "output": ""
            },
            {
                "code": "b = torch.randn(2, 3, 1)",
                "output": ""
            },
            {
                "code": "LU, pivots = torch.linalg.lu_factor(A)",
                "output": ""
            },
            {
                "code": "x = torch.lu_solve(b, LU, pivots)",
                "output": ""
            },
            {
                "code": "torch.dist(A @ x, b)",
                "output": "tensor(1.00000e-07 *\n       2.8312)"
            }
        ],
        "examples_count": 10,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.6",
        "removed_in": "2.9",
        "replaced_by": "torch.linalg.lu_solve"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.matrix_exp.html",
        "api": "torch.matrix_exp",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Streamlined API to encourage using `torch.linalg.matrix_exp()` as it more accurately reflects its placement within linear algebra operations.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": null,
        "replaced_by": "torch.linalg.matrix_exp"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.matrix_power.html",
        "api": "torch.matrix_power",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Redundant definition. The functionality directly maps to torch.linalg.matrix_power with no added advantages, simplifying the API surface.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.7",
        "removed_in": null,
        "replaced_by": "torch.linalg.matrix_power"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.lu_unpack.html",
        "api": "torch.lu_unpack",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "With the introduction of `torch.linalg` namespace, a more efficient and consistent LU decomposition method (`torch.linalg.lu`) is provided, serving as a replacement for `torch.lu_unpack`.",
        "has_examples": true,
        "examples": [
            {
                "code": "A = torch.randn(2, 3, 3)",
                "output": ""
            },
            {
                "code": "LU, pivots = torch.linalg.lu_factor(A)",
                "output": ""
            },
            {
                "code": "P, L, U = torch.lu_unpack(LU, pivots)\n# We can recover A from the factorization",
                "output": ""
            },
            {
                "code": "A_ = P @ L @ U",
                "output": ""
            },
            {
                "code": "torch.allclose(A, A_)\n# LU factorization of a rectangular matrix:",
                "output": "True"
            },
            {
                "code": "A = torch.randn(2, 3, 2)",
                "output": ""
            },
            {
                "code": "LU, pivots = torch.linalg.lu_factor(A)",
                "output": ""
            },
            {
                "code": "P, L, U = torch.lu_unpack(LU, pivots)\n# P, L, U are the same as returned by linalg.lu",
                "output": ""
            },
            {
                "code": "P_, L_, U_ = torch.linalg.lu(A)",
                "output": ""
            },
            {
                "code": "torch.allclose(P, P_) and torch.allclose(L, L_) and torch.allclose(U, U_)",
                "output": "True"
            }
        ],
        "examples_count": 10,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": null,
        "replaced_by": "torch.linalg.lu"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.mm.html",
        "api": "torch.mm",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "torch.mm does not support broadcasting, but torch.matmul provides this functionality for matrix products requiring broadcasting.",
        "has_examples": true,
        "examples": [
            {
                "code": "mat1 = torch.randn(2, 3)",
                "output": ""
            },
            {
                "code": "mat2 = torch.randn(3, 3)",
                "output": ""
            },
            {
                "code": "torch.mm(mat1, mat2)",
                "output": "tensor([[ 0.4851,  0.5037, -0.3633],\n        [-0.0760, -3.6705,  2.4784]])"
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.matmul"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.orgqr.html",
        "api": "torch.orgqr",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "To improve consistency and clarity within the PyTorch linear algebra module by aligning naming conventions with common mathematical terminology.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "2.10",
        "replaced_by": "torch.linalg.householder_product"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.pinverse.html",
        "api": "torch.pinverse",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Consolidation of linear algebra functionality under the torch.linalg namespace.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "2.9",
        "replaced_by": "torch.linalg.pinv"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.svd.html",
        "api": "torch.svd",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Improved functionality and alignment with other linear algebra functions in the torch.linalg namespace, enabling more consistent behavior and better integration with standard APIs.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.randn(5, 3)\na",
                "output": "U, S, Vh = torch.linalg.svd(A, full_matrices=not some)\nV = Vh.mH\n\n\nS = torch.linalg.svdvals(A)\n\ntensor([[ 0.2364, -0.7752,  0.6372],\n        [ 1.7201,  0.7394, -0.0504],\n        [-0.3371, -1.0584,  0.5296],\n        [ 0.3550, -0.4022,  1.5569],\n        [ 0.2445, -0.0158,  1.1414]])"
            },
            {
                "code": "u, s, v = torch.svd(a)\nu\ns\nv",
                "output": "tensor([[ 0.4027,  0.0287,  0.5434],\n        [-0.1946,  0.8833,  0.3679],\n        [ 0.4296, -0.2890,  0.5261],\n        [ 0.6604,  0.2717, -0.2618],\n        [ 0.4234,  0.2481, -0.4733]])\ntensor([2.3289, 2.0315, 0.7806])\ntensor([[-0.0199,  0.8766,  0.4809],\n        [-0.5080,  0.4054, -0.7600],\n        [ 0.8611,  0.2594, -0.4373]])"
            },
            {
                "code": "torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t()))",
                "output": "tensor(8.6531e-07)"
            },
            {
                "code": "a_big = torch.randn(7, 5, 3)",
                "output": ""
            },
            {
                "code": "u, s, v = torch.svd(a_big)",
                "output": ""
            },
            {
                "code": "torch.dist(a_big, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.mT))",
                "output": "tensor(2.6503e-06)"
            },
            {
                "code": "a = torch.randn(5, 3)\na",
                "output": "tensor([[ 0.2364, -0.7752,  0.6372],\n        [ 1.7201,  0.7394, -0.0504],\n        [-0.3371, -1.0584,  0.5296],\n        [ 0.3550, -0.4022,  1.5569],\n        [ 0.2445, -0.0158,  1.1414]])"
            },
            {
                "code": "u, s, v = torch.svd(a)\nu\ns\nv",
                "output": "tensor([[ 0.4027,  0.0287,  0.5434],\n        [-0.1946,  0.8833,  0.3679],\n        [ 0.4296, -0.2890,  0.5261],\n        [ 0.6604,  0.2717, -0.2618],\n        [ 0.4234,  0.2481, -0.4733]])\ntensor([2.3289, 2.0315, 0.7806])\ntensor([[-0.0199,  0.8766,  0.4809],\n        [-0.5080,  0.4054, -0.7600],\n        [ 0.8611,  0.2594, -0.4373]])"
            },
            {
                "code": "torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t()))",
                "output": "tensor(8.6531e-07)"
            },
            {
                "code": "a_big = torch.randn(7, 5, 3)",
                "output": ""
            },
            {
                "code": "u, s, v = torch.svd(a_big)",
                "output": ""
            },
            {
                "code": "torch.dist(a_big, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.mT))",
                "output": "tensor(2.6503e-06)"
            }
        ],
        "examples_count": 12,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.9.0",
        "removed_in": "2.0.0",
        "replaced_by": "torch.linalg.svd"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.qr.html",
        "api": "torch.qr",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "The new API (torch.linalg.qr) provides enhanced functionality with a consistent parameter interface ('mode' instead of 'some') and aligns better with other linear algebra functions in PyTorch.",
        "has_examples": true,
        "examples": [
            {
                "code": "a = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]])",
                "output": "Q, R = torch.linalg.qr(A)\n\nQ, R = torch.linalg.qr(A, mode=\"complete\")\n\n\nQ, R = torch.linalg.qr(A, mode=\"complete\")"
            },
            {
                "code": "q, r = torch.qr(a)\nq\nr",
                "output": "tensor([[-0.8571,  0.3943,  0.3314],\n        [-0.4286, -0.9029, -0.0343],\n        [ 0.2857, -0.1714,  0.9429]])\ntensor([[ -14.0000,  -21.0000,   14.0000],\n        [   0.0000, -175.0000,   70.0000],\n        [   0.0000,    0.0000,  -35.0000]])"
            },
            {
                "code": "torch.mm(q, r).round()",
                "output": "tensor([[  12.,  -51.,    4.],\n        [   6.,  167.,  -68.],\n        [  -4.,   24.,  -41.]])"
            },
            {
                "code": "torch.mm(q.t(), q).round()",
                "output": "tensor([[ 1.,  0.,  0.],\n        [ 0.,  1., -0.],\n        [ 0., -0.,  1.]])"
            },
            {
                "code": "a = torch.randn(3, 4, 5)",
                "output": ""
            },
            {
                "code": "q, r = torch.qr(a, some=False)",
                "output": ""
            },
            {
                "code": "torch.allclose(torch.matmul(q, r), a)",
                "output": "True"
            },
            {
                "code": "torch.allclose(torch.matmul(q.mT, q), torch.eye(5))",
                "output": "True"
            },
            {
                "code": "a = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]])",
                "output": ""
            },
            {
                "code": "q, r = torch.qr(a)\nq\nr",
                "output": "tensor([[-0.8571,  0.3943,  0.3314],\n        [-0.4286, -0.9029, -0.0343],\n        [ 0.2857, -0.1714,  0.9429]])\ntensor([[ -14.0000,  -21.0000,   14.0000],\n        [   0.0000, -175.0000,   70.0000],\n        [   0.0000,    0.0000,  -35.0000]])"
            },
            {
                "code": "torch.mm(q, r).round()",
                "output": "tensor([[  12.,  -51.,    4.],\n        [   6.,  167.,  -68.],\n        [  -4.,   24.,  -41.]])"
            },
            {
                "code": "torch.mm(q.t(), q).round()",
                "output": "tensor([[ 1.,  0.,  0.],\n        [ 0.,  1., -0.],\n        [ 0., -0.,  1.]])"
            },
            {
                "code": "a = torch.randn(3, 4, 5)",
                "output": ""
            },
            {
                "code": "q, r = torch.qr(a, some=False)",
                "output": ""
            },
            {
                "code": "torch.allclose(torch.matmul(q, r), a)",
                "output": "True"
            },
            {
                "code": "torch.allclose(torch.matmul(q.mT, q), torch.eye(5))",
                "output": "True"
            }
        ],
        "examples_count": 16,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "2.10",
        "replaced_by": "torch.linalg.qr"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.trapz.html",
        "api": "torch.trapz",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Unified naming convention with `torch.trapezoid` to avoid ambiguity and improve clarity.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": "3.0",
        "replaced_by": "torch.trapezoid"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.svd_lowrank.html",
        "api": "torch.svd_lowrank",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Performance optimization: torch.linalg.svd is 10x faster for dense matrices compared to torch.svd_lowrank. Additionally, torch.linalg.svd provides a deterministic full-rank solution for dense matrices.",
        "has_examples": false,
        "examples": [],
        "examples_count": 0,
        "extraction_method": "No Examples",
        "language": "Python",
        "deprecated_in": null,
        "removed_in": null,
        "replaced_by": "torch.linalg.svd"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.triangular_solve.html",
        "api": "torch.triangular_solve",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "To streamline and consolidate functionality into a new API `torch.linalg.solve_triangular`, which provides a clearer argument order and better aligns with other APIs in the `torch.linalg` module.",
        "has_examples": true,
        "examples": [
            {
                "code": "A = torch.randn(2, 2).triu()\nA",
                "output": "X = torch.linalg.solve_triangular(A, B)\n\ntensor([[ 1.1527, -1.0753],\n        [ 0.0000,  0.7986]])"
            },
            {
                "code": "b = torch.randn(2, 3)\nb",
                "output": "tensor([[-0.0210,  2.3513, -1.5492],\n        [ 1.5429,  0.7403, -1.0243]])"
            },
            {
                "code": "torch.triangular_solve(b, A)",
                "output": "torch.return_types.triangular_solve(\nsolution=tensor([[ 1.7841,  2.9046, -2.5405],\n        [ 1.9320,  0.9270, -1.2826]]),\ncloned_coefficient=tensor([[ 1.1527, -1.0753],\n        [ 0.0000,  0.7986]]))"
            },
            {
                "code": "A = torch.randn(2, 2).triu()\nA",
                "output": "tensor([[ 1.1527, -1.0753],\n        [ 0.0000,  0.7986]])"
            },
            {
                "code": "b = torch.randn(2, 3)\nb",
                "output": "tensor([[-0.0210,  2.3513, -1.5492],\n        [ 1.5429,  0.7403, -1.0243]])"
            },
            {
                "code": "torch.triangular_solve(b, A)",
                "output": "torch.return_types.triangular_solve(\nsolution=tensor([[ 1.7841,  2.9046, -2.5405],\n        [ 1.9320,  0.9270, -1.2826]]),\ncloned_coefficient=tensor([[ 1.1527, -1.0753],\n        [ 0.0000,  0.7986]]))"
            }
        ],
        "examples_count": 6,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.8",
        "removed_in": null,
        "replaced_by": "torch.linalg.solve_triangular"
    },
    {
        "source_url": "https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html",
        "api": "torch.use_deterministic_algorithms",
        "package": "PyTorch",
        "change_type": "Behavior Change",
        "reason": "Provides an alternative interface for controlling deterministic behavior with more granularity.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.use_deterministic_algorithms(True)",
                "output": "# Forward mode nondeterministic error"
            },
            {
                "code": "torch.randn(10, device='cuda').kthvalue(1)\n",
                "output": "RuntimeError: kthvalue CUDA does not have a deterministic implementation...\n\n# Backward mode nondeterministic error"
            },
            {
                "code": "torch.nn.AvgPool3d(1)(torch.randn(3, 4, 5, 6, requires_grad=True).cuda()).sum().backward()\n",
                "output": "RuntimeError: avg_pool3d_backward_cuda does not have a deterministic implementation..."
            }
        ],
        "examples_count": 3,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "1.8",
        "removed_in": null,
        "replaced_by": "torch.use_deterministic_algorithms"
    },
    {
        "source_url": "https://pytorch.org/docs/2.8/generated/torch.vmap.html",
        "api": "torch.vmap",
        "package": "PyTorch",
        "change_type": "API Deprecation",
        "reason": "Unified API naming convention for functional programming interface under `torch.func`.",
        "has_examples": true,
        "examples": [
            {
                "code": "torch.dot                            # [D], [D] -> []",
                "output": ""
            },
            {
                "code": "batched_dot = torch.func.vmap(torch.dot)  # [N, D], [N, D] -> [N]",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 5), torch.randn(2, 5)\nbatched_dot(x, y)",
                "output": ""
            },
            {
                "code": "batch_size, feature_size = 3, 5",
                "output": ""
            },
            {
                "code": "weights = torch.randn(feature_size, requires_grad=True)\n\ndef model(feature_vec):\n# Very simple linear model with activation\nreturn feature_vec.dot(weights).relu()\n",
                "output": ""
            },
            {
                "code": "examples = torch.randn(batch_size, feature_size)",
                "output": ""
            },
            {
                "code": "result = torch.vmap(model)(examples)",
                "output": ""
            },
            {
                "code": "batch_size, feature_size = 3, 5",
                "output": ""
            },
            {
                "code": "weights = torch.randn(feature_size, requires_grad=True)\n\ndef model(feature_vec):\n# Very simple linear model with activation\nreturn feature_vec.dot(weights).relu()\n",
                "output": ""
            },
            {
                "code": "examples = torch.randn(batch_size, feature_size)",
                "output": ""
            },
            {
                "code": "result = torch.vmap(model)(examples)\n# Setup",
                "output": ""
            },
            {
                "code": "N = 5",
                "output": ""
            },
            {
                "code": "f = lambda x: x ** 2",
                "output": ""
            },
            {
                "code": "x = torch.randn(N, requires_grad=True)",
                "output": ""
            },
            {
                "code": "y = f(x)",
                "output": ""
            },
            {
                "code": "I_N = torch.eye(N)\n\n# Sequential approach",
                "output": ""
            },
            {
                "code": "jacobian_rows = [torch.autograd.grad(y, x, v, retain_graph=True)[0]\nfor v in I_N.unbind()]",
                "output": ""
            },
            {
                "code": "jacobian = torch.stack(jacobian_rows)\n\n# vectorized gradient computation\ndef get_vjp(v):",
                "output": ""
            },
            {
                "code": "return torch.autograd.grad(y, x, v)",
                "output": ""
            },
            {
                "code": "jacobian = torch.vmap(get_vjp)(I_N)\n# Setup",
                "output": ""
            },
            {
                "code": "N = 5",
                "output": ""
            },
            {
                "code": "f = lambda x: x ** 2",
                "output": ""
            },
            {
                "code": "x = torch.randn(N, requires_grad=True)",
                "output": ""
            },
            {
                "code": "y = f(x)",
                "output": ""
            },
            {
                "code": "I_N = torch.eye(N)\n\n# Sequential approach",
                "output": ""
            },
            {
                "code": "jacobian_rows = [torch.autograd.grad(y, x, v, retain_graph=True)[0]\nfor v in I_N.unbind()]",
                "output": ""
            },
            {
                "code": "jacobian = torch.stack(jacobian_rows)\n\n# vectorized gradient computation\ndef get_vjp(v):",
                "output": ""
            },
            {
                "code": "return torch.autograd.grad(y, x, v)",
                "output": ""
            },
            {
                "code": "jacobian = torch.vmap(get_vjp)(I_N)",
                "output": ""
            },
            {
                "code": "torch.dot                            # [D], [D] -> []",
                "output": ""
            },
            {
                "code": "batched_dot = torch.vmap(torch.vmap(torch.dot))  # [N1, N0, D], [N1, N0, D] -> [N1, N0]",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 3, 5), torch.randn(2, 3, 5)\nbatched_dot(x, y) # tensor of size [2, 3]",
                "output": ""
            },
            {
                "code": "torch.dot                            # [D], [D] -> []",
                "output": ""
            },
            {
                "code": "batched_dot = torch.vmap(torch.vmap(torch.dot))  # [N1, N0, D], [N1, N0, D] -> [N1, N0]",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 3, 5), torch.randn(2, 3, 5)\nbatched_dot(x, y) # tensor of size [2, 3]",
                "output": ""
            },
            {
                "code": "torch.dot                            # [N], [N] -> []",
                "output": ""
            },
            {
                "code": "batched_dot = torch.vmap(torch.dot, in_dims=1)  # [N, D], [N, D] -> [D]",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 5), torch.randn(2, 5)\nbatched_dot(x, y)   # output is [5] instead of [2] if batched along the 0th dimension",
                "output": ""
            },
            {
                "code": "torch.dot                            # [N], [N] -> []",
                "output": ""
            },
            {
                "code": "batched_dot = torch.vmap(torch.dot, in_dims=1)  # [N, D], [N, D] -> [D]",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 5), torch.randn(2, 5)\nbatched_dot(x, y)   # output is [5] instead of [2] if batched along the 0th dimension",
                "output": ""
            },
            {
                "code": "torch.dot                            # [D], [D] -> []",
                "output": ""
            },
            {
                "code": "batched_dot = torch.vmap(torch.dot, in_dims=(0, None))  # [N, D], [D] -> [N]",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 5), torch.randn(5)\nbatched_dot(x, y) # second arg doesn't have a batch dim because in_dim[1] was None",
                "output": ""
            },
            {
                "code": "torch.dot                            # [D], [D] -> []",
                "output": ""
            },
            {
                "code": "batched_dot = torch.vmap(torch.dot, in_dims=(0, None))  # [N, D], [D] -> [N]",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 5), torch.randn(5)\nbatched_dot(x, y) # second arg doesn't have a batch dim because in_dim[1] was None",
                "output": ""
            },
            {
                "code": "f = lambda dict: torch.dot(dict['x'], dict['y'])",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 5), torch.randn(5)",
                "output": ""
            },
            {
                "code": "input = {'x': x, 'y': y}",
                "output": ""
            },
            {
                "code": "batched_dot = torch.vmap(f, in_dims=({'x': 0, 'y': None},))\nbatched_dot(input)",
                "output": ""
            },
            {
                "code": "f = lambda dict: torch.dot(dict['x'], dict['y'])",
                "output": ""
            },
            {
                "code": "x, y = torch.randn(2, 5), torch.randn(5)",
                "output": ""
            },
            {
                "code": "input = {'x': x, 'y': y}",
                "output": ""
            },
            {
                "code": "batched_dot = torch.vmap(f, in_dims=({'x': 0, 'y': None},))\nbatched_dot(input)",
                "output": ""
            },
            {
                "code": "f = lambda x: x ** 2",
                "output": ""
            },
            {
                "code": "x = torch.randn(2, 5)",
                "output": ""
            },
            {
                "code": "batched_pow = torch.vmap(f, out_dims=1)\nbatched_pow(x) # [5, 2]",
                "output": ""
            },
            {
                "code": "f = lambda x: x ** 2",
                "output": ""
            },
            {
                "code": "x = torch.randn(2, 5)",
                "output": ""
            },
            {
                "code": "batched_pow = torch.vmap(f, out_dims=1)\nbatched_pow(x) # [5, 2]",
                "output": ""
            },
            {
                "code": "x = torch.randn([2, 5])",
                "output": ""
            },
            {
                "code": "def fn(x, scale=4.):\nreturn x * scale\n",
                "output": ""
            },
            {
                "code": "batched_pow = torch.vmap(fn)",
                "output": ""
            },
            {
                "code": "assert torch.allclose(batched_pow(x), x * 4)",
                "output": ""
            },
            {
                "code": "batched_pow(x, scale=x) # scale is not batched, output has shape [2, 2, 5]",
                "output": ""
            },
            {
                "code": "x = torch.randn([2, 5])",
                "output": ""
            },
            {
                "code": "def fn(x, scale=4.):\nreturn x * scale\n",
                "output": ""
            },
            {
                "code": "batched_pow = torch.vmap(fn)",
                "output": ""
            },
            {
                "code": "assert torch.allclose(batched_pow(x), x * 4)",
                "output": ""
            },
            {
                "code": "batched_pow(x, scale=x) # scale is not batched, output has shape [2, 2, 5]",
                "output": ""
            }
        ],
        "examples_count": 71,
        "extraction_method": "Manual",
        "language": "Python",
        "deprecated_in": "2.0",
        "removed_in": "2.3",
        "replaced_by": "torch.func.vmap"
    }
]